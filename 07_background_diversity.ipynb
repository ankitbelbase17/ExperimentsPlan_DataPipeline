{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Background Diversity Metrics\n",
                "## Background Complexity & Uniformity Analysis\n",
                "\n",
                "This notebook measures the diversity and complexity of image backgrounds using computationally efficient border analysis (assuming the subject is centered)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup and Installation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q opencv-python-headless numpy matplotlib tqdm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import cv2\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from pathlib import Path\n",
                "from tqdm import tqdm\n",
                "import json\n",
                "\n",
                "print(f\"OpenCV: {cv2.__version__}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Background Extraction (Heuristic)\n",
                "For fashion datasets, the subject is usually centered. We analyze the **border regions** (margins) to characterize the background without needing heavy segmentation models."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_border_region(img, margin_percent=0.1):\n",
                "    \"\"\"Extract pixels from the image borders\"\"\"\n",
                "    h, w = img.shape[:2]\n",
                "    margin_h = int(h * margin_percent)\n",
                "    margin_w = int(w * margin_percent)\n",
                "    \n",
                "    # Top\n",
                "    top = img[:margin_h, :]\n",
                "    # Bottom\n",
                "    bottom = img[-margin_h:, :]\n",
                "    # Left (excluding corners already taken)\n",
                "    left = img[margin_h:-margin_h, :margin_w]\n",
                "    # Right\n",
                "    right = img[margin_h:-margin_h, -margin_w:]\n",
                "    \n",
                "    # Concatenate\n",
                "    if len(img.shape) == 3:\n",
                "        borders = np.vstack([top.reshape(-1, 3), bottom.reshape(-1, 3), left.reshape(-1, 3), right.reshape(-1, 3)])\n",
                "    else:\n",
                "        borders = np.concatenate([top.flatten(), bottom.flatten(), left.flatten(), right.flatten()])\n",
                "        \n",
                "    return borders"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Metrics\n",
                "- **Background Entropy**: Color diversity of the background.\n",
                "- **Edge Density**: Structural complexity (cluttered vs plain).\n",
                "- **Uniformity Score**: Percentage of background pixels close to the dominant color."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_entropy(pixels, bins=32):\n",
                "    if len(pixels) == 0: return 0.0\n",
                "    # Simple R,G,B histogram entropy\n",
                "    H, _ = np.histogramdd(pixels, bins=bins, range=((0, 256), (0, 256), (0, 256)), density=True)\n",
                "    prob = H.flatten()\n",
                "    prob = prob[prob > 0]\n",
                "    return -np.sum(prob * np.log(prob + 1e-12))\n",
                "\n",
                "def compute_edge_density(img_gray, margin_percent=0.1):\n",
                "    \"\"\"Compute edge density in border regions\"\"\"\n",
                "    edges = cv2.Canny(img_gray, 50, 150)\n",
                "    border_edges = get_border_region(edges, margin_percent)\n",
                "    \n",
                "    # Edge density = fraction of edge pixels\n",
                "    density = np.sum(border_edges > 0) / len(border_edges)\n",
                "    return density\n",
                "\n",
                "def is_uniform(pixels, tolerance=10):\n",
                "    \"\"\"Check if background is effectively monotonic (solid color)\"\"\"\n",
                "    curr_std = np.std(pixels, axis=0)\n",
                "    # If std dev is low in all channels, it's uniform\n",
                "    return np.mean(curr_std) < tolerance"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Evaluation Loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "config = {\n",
                "    'vitonhd': '/content/datasets/vitonhd',\n",
                "    'deepfashion1': '/content/datasets/deepfashion1',\n",
                "    'dresscode': '/content/datasets/dresscode',\n",
                "}\n",
                "config_path = Path('/content/datasets/dataset_config.json')\n",
                "if config_path.exists():\n",
                "    with open(config_path) as f:\n",
                "        config = json.load(f)\n",
                "\n",
                "def evaluate_background(dataset_name, dataset_path, max_images=300):\n",
                "    print(f\"\\nEvaluating: {dataset_name}\")\n",
                "    path = Path(dataset_path)\n",
                "    # Prioritize image folders\n",
                "    search = list(path.rglob('*.jpg')) + list(path.rglob('*.png'))\n",
                "    \n",
                "    if not search:\n",
                "        return None\n",
                "    \n",
                "    if len(search) > max_images:\n",
                "        import random\n",
                "        search = random.sample(search, max_images)\n",
                "        \n",
                "    entropies = []\n",
                "    edge_densities = []\n",
                "    uniform_count = 0\n",
                "    \n",
                "    for p in tqdm(search):\n",
                "        try:\n",
                "            img = cv2.imread(str(p))\n",
                "            if img is None: continue\n",
                "            \n",
                "            # Color Analysis\n",
                "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
                "            border_pixels = get_border_region(img_rgb)\n",
                "            entropies.append(compute_entropy(border_pixels))\n",
                "            if is_uniform(border_pixels):\n",
                "                uniform_count += 1\n",
                "                \n",
                "            # Edge Analysis\n",
                "            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
                "            edge_densities.append(compute_edge_density(img_gray))\n",
                "            \n",
                "        except Exception as e:\n",
                "            continue\n",
                "            \n",
                "    results = {\n",
                "        'dataset': dataset_name,\n",
                "        'avg_bg_entropy': float(np.mean(entropies)),\n",
                "        'avg_edge_density': float(np.mean(edge_densities)),\n",
                "        'percent_uniform_bg': float(uniform_count / len(search)),\n",
                "    }\n",
                "    \n",
                "    print(f\"Results for {dataset_name}:\")\n",
                "    print(f\"  - Avg Entropy: {results['avg_bg_entropy']:.4f}\")\n",
                "    print(f\"  - Avg Edge Density: {results['avg_edge_density']:.4f}\")\n",
                "    print(f\"  - Uniform Backgrounds: {results['percent_uniform_bg']:.2%}\")\n",
                "    \n",
                "    return results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "all_results = {}\n",
                "for name, path in config.items():\n",
                "    if name in ['vitonhd', 'deepfashion1', 'dresscode']:\n",
                "        res = evaluate_background(name.upper(), path)\n",
                "        if res:\n",
                "            all_results[name] = res"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if all_results:\n",
                "    datasets = list(all_results.keys())\n",
                "    entropy = [all_results[d]['avg_bg_entropy'] for d in datasets]\n",
                "    edges = [all_results[d]['avg_edge_density'] for d in datasets]\n",
                "    uniform = [all_results[d]['percent_uniform_bg'] for d in datasets]\n",
                "    \n",
                "    fig, ax = plt.subplots(1, 3, figsize=(18, 5))\n",
                "    \n",
                "    ax[0].bar(datasets, entropy, color='salmon')\n",
                "    ax[0].set_title(\"Background Color Entropy\")\n",
                "    \n",
                "    ax[1].bar(datasets, edges, color='skyblue')\n",
                "    ax[1].set_title(\"Background Edge Complexity\")\n",
                "    \n",
                "    ax[2].bar(datasets, uniform, color='lightgreen')\n",
                "    ax[2].set_title(\"Percentage of Uniform Backgrounds\")\n",
                "    ax[2].set_ylim(0, 1)\n",
                "    \n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save\n",
                "out_path = Path('/content/datasets/background_results.json')\n",
                "with open(out_path, 'w') as f:\n",
                "    json.dump(all_results, f, indent=2)\n",
                "print(f\"Saved to {out_path}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}