{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Body Pose Diversity Metrics\n",
                "## Pose Entropy & Average Pairwise Diversity\n",
                "\n",
                "This notebook calculates body pose diversity metrics using MoveNet Lightning (lightweight ~3MB)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup and Installation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies\n",
                "!pip install -q tensorflow tensorflow-hub numpy scipy matplotlib pillow tqdm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import tensorflow as tf\n",
                "import tensorflow_hub as hub\n",
                "import numpy as np\n",
                "from scipy import stats\n",
                "from scipy.spatial.distance import pdist, squareform\n",
                "import matplotlib.pyplot as plt\n",
                "from PIL import Image\n",
                "from pathlib import Path\n",
                "from tqdm import tqdm\n",
                "import json\n",
                "\n",
                "print(f\"TensorFlow version: {tf.__version__}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load MoveNet Lightning Model\n",
                "\n",
                "MoveNet Lightning is a very fast and lightweight pose estimation model (~3MB)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load MoveNet Lightning model from TensorFlow Hub\n",
                "model_url = \"https://tfhub.dev/google/movenet/singlepose/lightning/4\"\n",
                "model = hub.load(model_url)\n",
                "movenet = model.signatures['serving_default']\n",
                "\n",
                "print(\"MoveNet Lightning loaded successfully!\")\n",
                "\n",
                "# MoveNet keypoint indices\n",
                "KEYPOINT_NAMES = [\n",
                "    'nose', 'left_eye', 'right_eye', 'left_ear', 'right_ear',\n",
                "    'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow',\n",
                "    'left_wrist', 'right_wrist', 'left_hip', 'right_hip',\n",
                "    'left_knee', 'right_knee', 'left_ankle', 'right_ankle'\n",
                "]\n",
                "\n",
                "# Keypoint connections for visualization\n",
                "KEYPOINT_EDGES = [\n",
                "    (0, 1), (0, 2), (1, 3), (2, 4),  # Face\n",
                "    (5, 6), (5, 7), (7, 9), (6, 8), (8, 10),  # Arms\n",
                "    (5, 11), (6, 12), (11, 12),  # Torso\n",
                "    (11, 13), (13, 15), (12, 14), (14, 16)  # Legs\n",
                "]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Pose Extraction Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_and_preprocess_image(image_path, input_size=192):\n",
                "    \"\"\"Load and preprocess image for MoveNet\"\"\"\n",
                "    img = tf.io.read_file(str(image_path))\n",
                "    img = tf.image.decode_image(img, channels=3)\n",
                "    img = tf.image.resize_with_pad(img, input_size, input_size)\n",
                "    img = tf.cast(img, dtype=tf.int32)\n",
                "    return img\n",
                "\n",
                "def extract_keypoints(image_path):\n",
                "    \"\"\"Extract pose keypoints from a single image\"\"\"\n",
                "    try:\n",
                "        img = load_and_preprocess_image(image_path)\n",
                "        img = tf.expand_dims(img, axis=0)\n",
                "        \n",
                "        outputs = movenet(img)\n",
                "        keypoints = outputs['output_0'].numpy()[0, 0]  # Shape: (17, 3)\n",
                "        \n",
                "        return keypoints  # [y, x, confidence] for each keypoint\n",
                "    except Exception as e:\n",
                "        print(f\"Error processing {image_path}: {e}\")\n",
                "        return None\n",
                "\n",
                "def extract_all_poses(image_dir, max_images=None):\n",
                "    \"\"\"Extract poses from all images in directory\"\"\"\n",
                "    image_dir = Path(image_dir)\n",
                "    extensions = ['*.jpg', '*.jpeg', '*.png', '*.webp']\n",
                "    \n",
                "    image_paths = []\n",
                "    for ext in extensions:\n",
                "        image_paths.extend(list(image_dir.rglob(ext)))\n",
                "    \n",
                "    if max_images:\n",
                "        image_paths = image_paths[:max_images]\n",
                "    \n",
                "    print(f\"Processing {len(image_paths)} images...\")\n",
                "    \n",
                "    all_keypoints = []\n",
                "    valid_paths = []\n",
                "    \n",
                "    for path in tqdm(image_paths):\n",
                "        kp = extract_keypoints(path)\n",
                "        if kp is not None:\n",
                "            all_keypoints.append(kp)\n",
                "            valid_paths.append(path)\n",
                "    \n",
                "    return np.array(all_keypoints), valid_paths"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Pose Diversity Metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def normalize_pose(keypoints):\n",
                "    \"\"\"Normalize pose to be translation and scale invariant\"\"\"\n",
                "    # Use hip center as origin\n",
                "    left_hip = keypoints[11, :2]\n",
                "    right_hip = keypoints[12, :2]\n",
                "    hip_center = (left_hip + right_hip) / 2\n",
                "    \n",
                "    # Translate to origin\n",
                "    normalized = keypoints[:, :2] - hip_center\n",
                "    \n",
                "    # Scale by torso length (shoulder to hip)\n",
                "    left_shoulder = keypoints[5, :2]\n",
                "    right_shoulder = keypoints[6, :2]\n",
                "    shoulder_center = (left_shoulder + right_shoulder) / 2\n",
                "    torso_length = np.linalg.norm(shoulder_center - hip_center)\n",
                "    \n",
                "    if torso_length > 0.01:  # Avoid division by zero\n",
                "        normalized = normalized / torso_length\n",
                "    \n",
                "    return normalized.flatten()  # Return as 1D vector (34 values)\n",
                "\n",
                "def compute_pose_entropy(keypoints_list, num_bins=20):\n",
                "    \"\"\"\n",
                "    Compute pose entropy using histogram binning.\n",
                "    Higher entropy = more diverse poses.\n",
                "    \"\"\"\n",
                "    # Normalize all poses\n",
                "    normalized_poses = []\n",
                "    for kp in keypoints_list:\n",
                "        normalized = normalize_pose(kp)\n",
                "        normalized_poses.append(normalized)\n",
                "    \n",
                "    normalized_poses = np.array(normalized_poses)\n",
                "    \n",
                "    # Compute entropy for each dimension and average\n",
                "    entropies = []\n",
                "    for dim in range(normalized_poses.shape[1]):\n",
                "        values = normalized_poses[:, dim]\n",
                "        \n",
                "        # Create histogram\n",
                "        hist, _ = np.histogram(values, bins=num_bins, density=True)\n",
                "        hist = hist[hist > 0]  # Remove zero bins\n",
                "        \n",
                "        # Compute Shannon entropy\n",
                "        entropy = -np.sum(hist * np.log(hist + 1e-10)) / np.log(num_bins)\n",
                "        entropies.append(entropy)\n",
                "    \n",
                "    return np.mean(entropies), entropies\n",
                "\n",
                "def compute_pairwise_diversity(keypoints_list, max_pairs=5000):\n",
                "    \"\"\"\n",
                "    Compute average pairwise distance between poses.\n",
                "    Higher value = more diverse poses.\n",
                "    \"\"\"\n",
                "    # Normalize all poses\n",
                "    normalized_poses = []\n",
                "    for kp in keypoints_list:\n",
                "        normalized = normalize_pose(kp)\n",
                "        normalized_poses.append(normalized)\n",
                "    \n",
                "    normalized_poses = np.array(normalized_poses)\n",
                "    \n",
                "    # Sample if too many poses (for efficiency)\n",
                "    n = len(normalized_poses)\n",
                "    if n * (n - 1) / 2 > max_pairs:\n",
                "        indices = np.random.choice(n, size=int(np.sqrt(2 * max_pairs)), replace=False)\n",
                "        normalized_poses = normalized_poses[indices]\n",
                "    \n",
                "    # Compute pairwise distances\n",
                "    distances = pdist(normalized_poses, metric='euclidean')\n",
                "    \n",
                "    return np.mean(distances), np.std(distances), distances"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Load Dataset Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Try to load config from dataset download notebook\n",
                "config_path = Path('/content/datasets/dataset_config.json')\n",
                "\n",
                "if config_path.exists():\n",
                "    with open(config_path) as f:\n",
                "        config = json.load(f)\n",
                "    print(\"Loaded dataset configuration\")\n",
                "else:\n",
                "    # Manual configuration\n",
                "    config = {\n",
                "        'vitonhd': '/content/datasets/vitonhd',\n",
                "        'deepfashion1': '/content/datasets/deepfashion1',\n",
                "        'dresscode': '/content/datasets/dresscode',\n",
                "    }\n",
                "    print(\"Using default paths - run 01_dataset_download.ipynb first\")\n",
                "\n",
                "print(f\"Dataset paths: {config}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Evaluate Pose Diversity on Datasets"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def evaluate_pose_diversity(dataset_name, dataset_path, max_images=500):\n",
                "    \"\"\"Evaluate pose diversity metrics for a dataset\"\"\"\n",
                "    print(f\"\\n{'='*60}\")\n",
                "    print(f\"Evaluating: {dataset_name}\")\n",
                "    print(f\"{'='*60}\")\n",
                "    \n",
                "    dataset_path = Path(dataset_path)\n",
                "    if not dataset_path.exists():\n",
                "        print(f\"Dataset path not found: {dataset_path}\")\n",
                "        return None\n",
                "    \n",
                "    # Extract poses\n",
                "    keypoints, paths = extract_all_poses(dataset_path, max_images)\n",
                "    \n",
                "    if len(keypoints) == 0:\n",
                "        print(\"No valid poses extracted\")\n",
                "        return None\n",
                "    \n",
                "    print(f\"\\nExtracted {len(keypoints)} valid poses\")\n",
                "    \n",
                "    # Compute metrics\n",
                "    print(\"\\nComputing pose entropy...\")\n",
                "    entropy, dim_entropies = compute_pose_entropy(keypoints)\n",
                "    \n",
                "    print(\"Computing pairwise diversity...\")\n",
                "    avg_distance, std_distance, distances = compute_pairwise_diversity(keypoints)\n",
                "    \n",
                "    results = {\n",
                "        'dataset': dataset_name,\n",
                "        'num_images': len(keypoints),\n",
                "        'pose_entropy': float(entropy),\n",
                "        'avg_pairwise_diversity': float(avg_distance),\n",
                "        'std_pairwise_diversity': float(std_distance),\n",
                "    }\n",
                "    \n",
                "    print(f\"\\nResults for {dataset_name}:\")\n",
                "    print(f\"  - Pose Entropy: {entropy:.4f}\")\n",
                "    print(f\"  - Avg Pairwise Diversity: {avg_distance:.4f} (Â±{std_distance:.4f})\")\n",
                "    \n",
                "    return results, keypoints, distances"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluate all datasets\n",
                "all_results = {}\n",
                "\n",
                "for name, path in config.items():\n",
                "    if name in ['vitonhd', 'deepfashion1', 'dresscode']:\n",
                "        result = evaluate_pose_diversity(name.upper(), path, max_images=500)\n",
                "        if result:\n",
                "            all_results[name] = result[0]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def visualize_pose(image_path, keypoints, ax=None):\n",
                "    \"\"\"Visualize pose on image\"\"\"\n",
                "    img = Image.open(image_path)\n",
                "    img = np.array(img)\n",
                "    h, w = img.shape[:2]\n",
                "    \n",
                "    if ax is None:\n",
                "        fig, ax = plt.subplots(figsize=(6, 8))\n",
                "    \n",
                "    ax.imshow(img)\n",
                "    \n",
                "    # Draw keypoints\n",
                "    for i, (y, x, conf) in enumerate(keypoints):\n",
                "        if conf > 0.3:\n",
                "            ax.plot(x * w, y * h, 'ro', markersize=5)\n",
                "    \n",
                "    # Draw skeleton\n",
                "    for start, end in KEYPOINT_EDGES:\n",
                "        if keypoints[start, 2] > 0.3 and keypoints[end, 2] > 0.3:\n",
                "            y1, x1 = keypoints[start, :2]\n",
                "            y2, x2 = keypoints[end, :2]\n",
                "            ax.plot([x1 * w, x2 * w], [y1 * h, y2 * h], 'g-', linewidth=2)\n",
                "    \n",
                "    ax.axis('off')\n",
                "    return ax\n",
                "\n",
                "# Visualize sample poses\n",
                "def visualize_samples(dataset_path, num_samples=4):\n",
                "    \"\"\"Visualize sample poses from dataset\"\"\"\n",
                "    dataset_path = Path(dataset_path)\n",
                "    if not dataset_path.exists():\n",
                "        return\n",
                "    \n",
                "    images = list(dataset_path.rglob('*.jpg'))[:num_samples] + \\\n",
                "             list(dataset_path.rglob('*.png'))[:num_samples]\n",
                "    images = images[:num_samples]\n",
                "    \n",
                "    if not images:\n",
                "        return\n",
                "    \n",
                "    fig, axes = plt.subplots(1, len(images), figsize=(4*len(images), 6))\n",
                "    if len(images) == 1:\n",
                "        axes = [axes]\n",
                "    \n",
                "    for ax, img_path in zip(axes, images):\n",
                "        kp = extract_keypoints(img_path)\n",
                "        if kp is not None:\n",
                "            visualize_pose(img_path, kp, ax)\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize sample poses from each dataset\n",
                "for name, path in config.items():\n",
                "    if name in ['vitonhd', 'deepfashion1', 'dresscode']:\n",
                "        print(f\"\\n{name.upper()} Sample Poses:\")\n",
                "        visualize_samples(path, num_samples=4)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compare metrics across datasets\n",
                "if all_results:\n",
                "    datasets = list(all_results.keys())\n",
                "    entropies = [all_results[d]['pose_entropy'] for d in datasets]\n",
                "    diversities = [all_results[d]['avg_pairwise_diversity'] for d in datasets]\n",
                "    \n",
                "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
                "    \n",
                "    # Pose Entropy comparison\n",
                "    axes[0].bar(datasets, entropies, color=['#3498db', '#e74c3c', '#2ecc71'])\n",
                "    axes[0].set_ylabel('Pose Entropy')\n",
                "    axes[0].set_title('Pose Entropy by Dataset')\n",
                "    axes[0].set_ylim(0, 1)\n",
                "    \n",
                "    # Pairwise Diversity comparison\n",
                "    axes[1].bar(datasets, diversities, color=['#3498db', '#e74c3c', '#2ecc71'])\n",
                "    axes[1].set_ylabel('Avg Pairwise Diversity')\n",
                "    axes[1].set_title('Pairwise Pose Diversity by Dataset')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Save Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save results to JSON\n",
                "results_path = Path('/content/datasets/pose_diversity_results.json')\n",
                "\n",
                "with open(results_path, 'w') as f:\n",
                "    json.dump(all_results, f, indent=2)\n",
                "\n",
                "print(f\"Results saved to: {results_path}\")\n",
                "\n",
                "# Print summary table\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"POSE DIVERSITY METRICS SUMMARY\")\n",
                "print(\"=\"*60)\n",
                "print(f\"{'Dataset':<15} {'Pose Entropy':<15} {'Pairwise Div.':<15}\")\n",
                "print(\"-\"*45)\n",
                "for name, results in all_results.items():\n",
                "    print(f\"{name:<15} {results['pose_entropy']:<15.4f} {results['avg_pairwise_diversity']:<15.4f}\")\n",
                "print(\"=\"*60)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}