{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Cloth Diversity Metrics\n",
                "## Feature Distribution Analysis with MobileNetV3\n",
                "\n",
                "This notebook measures clothing appearance diversity using pretrained MobileNetV3-Small features (~5MB)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup and Installation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies\n",
                "!pip install -q torch torchvision numpy scipy matplotlib pillow tqdm scikit-learn"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torchvision.models as models\n",
                "import torchvision.transforms as transforms\n",
                "import numpy as np\n",
                "from scipy.spatial.distance import pdist, cdist\n",
                "from sklearn.decomposition import PCA\n",
                "import matplotlib.pyplot as plt\n",
                "from PIL import Image\n",
                "from pathlib import Path\n",
                "from tqdm import tqdm\n",
                "import json\n",
                "\n",
                "# Check device\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Using device: {device}\")\n",
                "print(f\"PyTorch version: {torch.__version__}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load MobileNetV3-Small Feature Extractor"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class ClothFeatureExtractor(nn.Module):\n",
                "    \"\"\"Feature extractor using MobileNetV3-Small backbone\"\"\"\n",
                "    \n",
                "    def __init__(self):\n",
                "        super().__init__()\n",
                "        # Load pretrained MobileNetV3-Small\n",
                "        mobilenet = models.mobilenet_v3_small(weights=models.MobileNet_V3_Small_Weights.IMAGENET1K_V1)\n",
                "        \n",
                "        # Remove classifier, keep feature extractor\n",
                "        self.features = mobilenet.features\n",
                "        self.avgpool = mobilenet.avgpool\n",
                "        \n",
                "        # Feature dimension: 576 for MobileNetV3-Small\n",
                "        self.feature_dim = 576\n",
                "        \n",
                "    def forward(self, x):\n",
                "        x = self.features(x)\n",
                "        x = self.avgpool(x)\n",
                "        x = x.flatten(1)\n",
                "        return x\n",
                "\n",
                "# Initialize model\n",
                "model = ClothFeatureExtractor().to(device)\n",
                "model.eval()\n",
                "\n",
                "print(f\"MobileNetV3-Small loaded (feature dim: {model.feature_dim})\")\n",
                "\n",
                "# Image preprocessing\n",
                "preprocess = transforms.Compose([\n",
                "    transforms.Resize((224, 224)),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
                "])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Feature Extraction Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "@torch.no_grad()\n",
                "def extract_features(image_path):\n",
                "    \"\"\"Extract features from a single image\"\"\"\n",
                "    try:\n",
                "        img = Image.open(image_path).convert('RGB')\n",
                "        img_tensor = preprocess(img).unsqueeze(0).to(device)\n",
                "        features = model(img_tensor)\n",
                "        return features.cpu().numpy().flatten()\n",
                "    except Exception as e:\n",
                "        print(f\"Error processing {image_path}: {e}\")\n",
                "        return None\n",
                "\n",
                "@torch.no_grad()\n",
                "def extract_features_batch(image_paths, batch_size=32):\n",
                "    \"\"\"Extract features from multiple images in batches\"\"\"\n",
                "    all_features = []\n",
                "    valid_paths = []\n",
                "    \n",
                "    for i in tqdm(range(0, len(image_paths), batch_size), desc=\"Extracting features\"):\n",
                "        batch_paths = image_paths[i:i+batch_size]\n",
                "        batch_tensors = []\n",
                "        batch_valid_paths = []\n",
                "        \n",
                "        for path in batch_paths:\n",
                "            try:\n",
                "                img = Image.open(path).convert('RGB')\n",
                "                batch_tensors.append(preprocess(img))\n",
                "                batch_valid_paths.append(path)\n",
                "            except Exception as e:\n",
                "                continue\n",
                "        \n",
                "        if batch_tensors:\n",
                "            batch = torch.stack(batch_tensors).to(device)\n",
                "            features = model(batch).cpu().numpy()\n",
                "            all_features.extend(features)\n",
                "            valid_paths.extend(batch_valid_paths)\n",
                "    \n",
                "    return np.array(all_features), valid_paths\n",
                "\n",
                "def get_image_paths(directory, max_images=None):\n",
                "    \"\"\"Get all image paths from directory\"\"\"\n",
                "    directory = Path(directory)\n",
                "    extensions = ['*.jpg', '*.jpeg', '*.png', '*.webp']\n",
                "    \n",
                "    image_paths = []\n",
                "    for ext in extensions:\n",
                "        image_paths.extend(list(directory.rglob(ext)))\n",
                "    \n",
                "    if max_images:\n",
                "        image_paths = image_paths[:max_images]\n",
                "    \n",
                "    return image_paths"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Cloth Diversity Metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_feature_statistics(features):\n",
                "    \"\"\"Compute feature distribution statistics\"\"\"\n",
                "    mean = np.mean(features, axis=0)\n",
                "    std = np.std(features, axis=0)\n",
                "    variance = np.var(features, axis=0)\n",
                "    \n",
                "    return {\n",
                "        'mean_feature_magnitude': float(np.linalg.norm(mean)),\n",
                "        'avg_feature_std': float(np.mean(std)),\n",
                "        'total_variance': float(np.sum(variance)),\n",
                "        'avg_variance_per_dim': float(np.mean(variance)),\n",
                "    }\n",
                "\n",
                "def compute_pairwise_cosine_diversity(features, max_pairs=10000):\n",
                "    \"\"\"Compute average pairwise cosine distance\"\"\"\n",
                "    n = len(features)\n",
                "    \n",
                "    # Sample if too many features\n",
                "    if n * (n - 1) / 2 > max_pairs:\n",
                "        indices = np.random.choice(n, size=int(np.sqrt(2 * max_pairs)), replace=False)\n",
                "        features = features[indices]\n",
                "    \n",
                "    # Normalize features for cosine distance\n",
                "    normalized = features / (np.linalg.norm(features, axis=1, keepdims=True) + 1e-10)\n",
                "    \n",
                "    # Compute pairwise cosine distances\n",
                "    distances = pdist(normalized, metric='cosine')\n",
                "    \n",
                "    return {\n",
                "        'avg_cosine_distance': float(np.mean(distances)),\n",
                "        'std_cosine_distance': float(np.std(distances)),\n",
                "        'min_cosine_distance': float(np.min(distances)),\n",
                "        'max_cosine_distance': float(np.max(distances)),\n",
                "    }\n",
                "\n",
                "def compute_pairwise_euclidean_diversity(features, max_pairs=10000):\n",
                "    \"\"\"Compute average pairwise Euclidean distance\"\"\"\n",
                "    n = len(features)\n",
                "    \n",
                "    # Sample if too many features\n",
                "    if n * (n - 1) / 2 > max_pairs:\n",
                "        indices = np.random.choice(n, size=int(np.sqrt(2 * max_pairs)), replace=False)\n",
                "        features = features[indices]\n",
                "    \n",
                "    # Compute pairwise Euclidean distances\n",
                "    distances = pdist(features, metric='euclidean')\n",
                "    \n",
                "    return {\n",
                "        'avg_euclidean_distance': float(np.mean(distances)),\n",
                "        'std_euclidean_distance': float(np.std(distances)),\n",
                "    }\n",
                "\n",
                "def compute_feature_entropy(features, num_clusters=20):\n",
                "    \"\"\"Compute feature entropy using PCA + clustering\"\"\"\n",
                "    from sklearn.cluster import MiniBatchKMeans\n",
                "    \n",
                "    # Reduce dimensionality with PCA\n",
                "    pca = PCA(n_components=min(50, features.shape[1]))\n",
                "    features_pca = pca.fit_transform(features)\n",
                "    \n",
                "    # Cluster features\n",
                "    kmeans = MiniBatchKMeans(n_clusters=num_clusters, random_state=42, n_init=3)\n",
                "    labels = kmeans.fit_predict(features_pca)\n",
                "    \n",
                "    # Compute entropy of cluster distribution\n",
                "    counts = np.bincount(labels, minlength=num_clusters)\n",
                "    probs = counts / len(labels)\n",
                "    probs = probs[probs > 0]  # Remove zero probabilities\n",
                "    \n",
                "    entropy = -np.sum(probs * np.log(probs))\n",
                "    max_entropy = np.log(num_clusters)\n",
                "    normalized_entropy = entropy / max_entropy\n",
                "    \n",
                "    return {\n",
                "        'feature_entropy': float(entropy),\n",
                "        'normalized_entropy': float(normalized_entropy),\n",
                "        'pca_explained_variance_ratio': pca.explained_variance_ratio_.tolist()[:10],\n",
                "    }"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Load Dataset Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Try to load config from dataset download notebook\n",
                "config_path = Path('/content/datasets/dataset_config.json')\n",
                "\n",
                "if config_path.exists():\n",
                "    with open(config_path) as f:\n",
                "        config = json.load(f)\n",
                "    print(\"Loaded dataset configuration\")\n",
                "else:\n",
                "    config = {\n",
                "        'vitonhd': '/content/datasets/vitonhd',\n",
                "        'deepfashion1': '/content/datasets/deepfashion1',\n",
                "        'dresscode': '/content/datasets/dresscode',\n",
                "    }\n",
                "    print(\"Using default paths\")\n",
                "\n",
                "print(f\"Dataset paths: {config}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Evaluate Cloth Diversity"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def evaluate_cloth_diversity(dataset_name, dataset_path, max_images=500):\n",
                "    \"\"\"Evaluate cloth diversity metrics for a dataset\"\"\"\n",
                "    print(f\"\\n{'='*60}\")\n",
                "    print(f\"Evaluating: {dataset_name}\")\n",
                "    print(f\"{'='*60}\")\n",
                "    \n",
                "    dataset_path = Path(dataset_path)\n",
                "    if not dataset_path.exists():\n",
                "        print(f\"Dataset path not found: {dataset_path}\")\n",
                "        return None, None\n",
                "    \n",
                "    # Get image paths (look for cloth-specific directories)\n",
                "    cloth_dirs = ['cloth', 'clothes', 'garment', 'garments']\n",
                "    image_paths = []\n",
                "    \n",
                "    for cloth_dir in cloth_dirs:\n",
                "        cloth_path = dataset_path / cloth_dir\n",
                "        if cloth_path.exists():\n",
                "            image_paths.extend(get_image_paths(cloth_path, max_images))\n",
                "    \n",
                "    # If no cloth-specific directory, use all images\n",
                "    if not image_paths:\n",
                "        image_paths = get_image_paths(dataset_path, max_images)\n",
                "    \n",
                "    if not image_paths:\n",
                "        print(\"No images found\")\n",
                "        return None, None\n",
                "    \n",
                "    print(f\"Found {len(image_paths)} images\")\n",
                "    \n",
                "    # Extract features\n",
                "    features, valid_paths = extract_features_batch(image_paths)\n",
                "    print(f\"Extracted features for {len(features)} images\")\n",
                "    \n",
                "    if len(features) == 0:\n",
                "        print(\"No valid features extracted\")\n",
                "        return None, None\n",
                "    \n",
                "    # Compute metrics\n",
                "    print(\"\\nComputing metrics...\")\n",
                "    \n",
                "    results = {\n",
                "        'dataset': dataset_name,\n",
                "        'num_images': len(features),\n",
                "        'feature_dim': features.shape[1],\n",
                "    }\n",
                "    \n",
                "    results.update(compute_feature_statistics(features))\n",
                "    results.update(compute_pairwise_cosine_diversity(features))\n",
                "    results.update(compute_pairwise_euclidean_diversity(features))\n",
                "    results.update(compute_feature_entropy(features))\n",
                "    \n",
                "    print(f\"\\nResults for {dataset_name}:\")\n",
                "    print(f\"  - Avg Cosine Distance: {results['avg_cosine_distance']:.4f}\")\n",
                "    print(f\"  - Avg Euclidean Distance: {results['avg_euclidean_distance']:.4f}\")\n",
                "    print(f\"  - Normalized Entropy: {results['normalized_entropy']:.4f}\")\n",
                "    print(f\"  - Total Variance: {results['total_variance']:.4f}\")\n",
                "    \n",
                "    return results, features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluate all datasets\n",
                "all_results = {}\n",
                "all_features = {}\n",
                "\n",
                "for name, path in config.items():\n",
                "    if name in ['vitonhd', 'deepfashion1', 'dresscode']:\n",
                "        results, features = evaluate_cloth_diversity(name.upper(), path, max_images=500)\n",
                "        if results:\n",
                "            all_results[name] = results\n",
                "            all_features[name] = features"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def visualize_feature_space(features_dict, title=\"Feature Space Visualization\"):\n",
                "    \"\"\"Visualize feature space using PCA\"\"\"\n",
                "    if not features_dict:\n",
                "        return\n",
                "    \n",
                "    # Combine all features\n",
                "    all_features = []\n",
                "    labels = []\n",
                "    \n",
                "    for name, features in features_dict.items():\n",
                "        all_features.append(features[:200])  # Limit for visualization\n",
                "        labels.extend([name] * len(features[:200]))\n",
                "    \n",
                "    combined = np.vstack(all_features)\n",
                "    \n",
                "    # PCA to 2D\n",
                "    pca = PCA(n_components=2)\n",
                "    features_2d = pca.fit_transform(combined)\n",
                "    \n",
                "    # Plot\n",
                "    fig, ax = plt.subplots(figsize=(10, 8))\n",
                "    \n",
                "    colors = {'vitonhd': '#3498db', 'deepfashion1': '#e74c3c', 'dresscode': '#2ecc71'}\n",
                "    \n",
                "    start_idx = 0\n",
                "    for name, features in features_dict.items():\n",
                "        end_idx = start_idx + len(features[:200])\n",
                "        ax.scatter(\n",
                "            features_2d[start_idx:end_idx, 0],\n",
                "            features_2d[start_idx:end_idx, 1],\n",
                "            label=name.upper(),\n",
                "            c=colors.get(name, '#333'),\n",
                "            alpha=0.6,\n",
                "            s=30\n",
                "        )\n",
                "        start_idx = end_idx\n",
                "    \n",
                "    ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
                "    ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
                "    ax.set_title(title)\n",
                "    ax.legend()\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "visualize_feature_space(all_features, \"Cloth Feature Space (PCA)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compare metrics across datasets\n",
                "if all_results:\n",
                "    datasets = list(all_results.keys())\n",
                "    \n",
                "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
                "    \n",
                "    # Cosine Distance\n",
                "    values = [all_results[d]['avg_cosine_distance'] for d in datasets]\n",
                "    axes[0, 0].bar(datasets, values, color=['#3498db', '#e74c3c', '#2ecc71'][:len(datasets)])\n",
                "    axes[0, 0].set_ylabel('Avg Cosine Distance')\n",
                "    axes[0, 0].set_title('Cloth Diversity (Cosine Distance)')\n",
                "    \n",
                "    # Euclidean Distance\n",
                "    values = [all_results[d]['avg_euclidean_distance'] for d in datasets]\n",
                "    axes[0, 1].bar(datasets, values, color=['#3498db', '#e74c3c', '#2ecc71'][:len(datasets)])\n",
                "    axes[0, 1].set_ylabel('Avg Euclidean Distance')\n",
                "    axes[0, 1].set_title('Cloth Diversity (Euclidean Distance)')\n",
                "    \n",
                "    # Normalized Entropy\n",
                "    values = [all_results[d]['normalized_entropy'] for d in datasets]\n",
                "    axes[1, 0].bar(datasets, values, color=['#3498db', '#e74c3c', '#2ecc71'][:len(datasets)])\n",
                "    axes[1, 0].set_ylabel('Normalized Entropy')\n",
                "    axes[1, 0].set_title('Cloth Feature Entropy')\n",
                "    axes[1, 0].set_ylim(0, 1)\n",
                "    \n",
                "    # Total Variance\n",
                "    values = [all_results[d]['total_variance'] for d in datasets]\n",
                "    axes[1, 1].bar(datasets, values, color=['#3498db', '#e74c3c', '#2ecc71'][:len(datasets)])\n",
                "    axes[1, 1].set_ylabel('Total Variance')\n",
                "    axes[1, 1].set_title('Cloth Feature Variance')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Save Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save results\n",
                "results_path = Path('/content/datasets/cloth_diversity_results.json')\n",
                "\n",
                "# Remove non-serializable items\n",
                "save_results = {}\n",
                "for name, results in all_results.items():\n",
                "    save_results[name] = {k: v for k, v in results.items()}\n",
                "\n",
                "with open(results_path, 'w') as f:\n",
                "    json.dump(save_results, f, indent=2)\n",
                "\n",
                "print(f\"Results saved to: {results_path}\")\n",
                "\n",
                "# Print summary\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"CLOTH DIVERSITY METRICS SUMMARY\")\n",
                "print(\"=\"*70)\n",
                "print(f\"{'Dataset':<15} {'Cosine Dist':<12} {'Eucl. Dist':<12} {'Entropy':<12} {'Variance':<12}\")\n",
                "print(\"-\"*63)\n",
                "for name, r in all_results.items():\n",
                "    print(f\"{name:<15} {r['avg_cosine_distance']:<12.4f} {r['avg_euclidean_distance']:<12.2f} {r['normalized_entropy']:<12.4f} {r['total_variance']:<12.2f}\")\n",
                "print(\"=\"*70)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}