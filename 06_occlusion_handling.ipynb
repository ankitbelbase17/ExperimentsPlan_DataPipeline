{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Occlusion Handling Metrics\n",
                "## Pose Visibility & Occlusion Rate Analysis\n",
                "\n",
                "This notebook evaluates the degree of occlusion in the dataset using MoveNet keypoint confidence scores. Low confidence scores for body parts typically indicate occlusion or poor visibility."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup and Installation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q tensorflow tensorflow-hub numpy matplotlib tqdm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import tensorflow as tf\n",
                "import tensorflow_hub as hub\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from pathlib import Path\n",
                "from tqdm import tqdm\n",
                "import json\n",
                "\n",
                "print(f\"TensorFlow: {tf.__version__}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load MoveNet Model\n",
                "Reusing the lightweight MoveNet Lightning model from the Pose Diversity metric."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_url = \"https://tfhub.dev/google/movenet/singlepose/lightning/4\"\n",
                "model = hub.load(model_url)\n",
                "movenet = model.signatures['serving_default']\n",
                "\n",
                "print(\"MoveNet loaded.\")\n",
                "\n",
                "KEYPOINT_NAMES = [\n",
                "    'nose', 'left_eye', 'right_eye', 'left_ear', 'right_ear',\n",
                "    'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow',\n",
                "    'left_wrist', 'right_wrist', 'left_hip', 'right_hip',\n",
                "    'left_knee', 'right_knee', 'left_ankle', 'right_ankle'\n",
                "]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def extract_keypoints(image_path):\n",
                "    try:\n",
                "        img = tf.io.read_file(str(image_path))\n",
                "        img = tf.image.decode_image(img, channels=3)\n",
                "        img = tf.image.resize_with_pad(img, 192, 192)\n",
                "        input_img = tf.cast(img, dtype=tf.int32)\n",
                "        input_img = tf.expand_dims(input_img, axis=0)\n",
                "        \n",
                "        outputs = movenet(input_img)\n",
                "        keypoints = outputs['output_0'].numpy()[0, 0] # (17, 3) [y, x, conf]\n",
                "        return keypoints\n",
                "    except Exception as e:\n",
                "        return None"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Occlusion Metrics\n",
                "We define occlusion metrics based on the confidence scores of keypoints.\n",
                "- **Occlusion Rate**: Percentage of keypoints with confidence < Threshold (e.g., 0.3).\n",
                "- **Detection Score**: Average confidence across all keypoints.\n",
                "- **Critical Part Occlusion**: Frequency of missing \"critical\" parts (e.g., shoulders, hips for fashion)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def calculate_occlusion_metrics(keypoints, threshold=0.3):\n",
                "    if keypoints is None:\n",
                "        return None\n",
                "    \n",
                "    confidences = keypoints[:, 2]\n",
                "    \n",
                "    # 1. Average Confidence (Visibility Score)\n",
                "    avg_conf = np.mean(confidences)\n",
                "    \n",
                "    # 2. Occlusion Rate (Percentage of parts missing)\n",
                "    missing_count = np.sum(confidences < threshold)\n",
                "    occlusion_rate = missing_count / len(confidences)\n",
                "    \n",
                "    # 3. Categorical Occlusion\n",
                "    # specific parts (Fashion relevant: Shoulders, Hips, Knees)\n",
                "    # Shoulders: 5, 6. Hips: 11, 12.\n",
                "    torso_indices = [5, 6, 11, 12]\n",
                "    torso_conf = confidences[torso_indices]\n",
                "    torso_occlusion_rate = np.sum(torso_conf < threshold) / len(torso_indices)\n",
                "    \n",
                "    return {\n",
                "        'avg_confidence': float(avg_conf),\n",
                "        'occlusion_rate': float(occlusion_rate),\n",
                "        'torso_occlusion_rate': float(torso_occlusion_rate)\n",
                "    }"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Evaluation Loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "config = {\n",
                "    'vitonhd': '/content/datasets/vitonhd',\n",
                "    'deepfashion1': '/content/datasets/deepfashion1',\n",
                "    'dresscode': '/content/datasets/dresscode',\n",
                "}\n",
                "\n",
                "# Try to load real config if exists\n",
                "config_path = Path('/content/datasets/dataset_config.json')\n",
                "if config_path.exists():\n",
                "    with open(config_path) as f:\n",
                "        config = json.load(f)\n",
                "\n",
                "def evaluate_occlusion(dataset_name, dataset_path, max_images=300):\n",
                "    print(f\"\\nEvaluating: {dataset_name}\")\n",
                "    path = Path(dataset_path)\n",
                "    images = list(path.rglob('*.jpg')) + list(path.rglob('*.png'))\n",
                "    \n",
                "    if not images:\n",
                "        print(\"No images found.\")\n",
                "        return None\n",
                "        \n",
                "    if len(images) > max_images:\n",
                "        import random\n",
                "        images = random.sample(images, max_images)\n",
                "        \n",
                "    metrics_list = []\n",
                "    \n",
                "    for img_path in tqdm(images):\n",
                "        kps = extract_keypoints(img_path)\n",
                "        m = calculate_occlusion_metrics(kps)\n",
                "        if m:\n",
                "            metrics_list.append(m)\n",
                "            \n",
                "    if not metrics_list:\n",
                "        return None\n",
                "        \n",
                "    # Aggregate\n",
                "    avg_occlusion = np.mean([m['occlusion_rate'] for m in metrics_list])\n",
                "    avg_confidence = np.mean([m['avg_confidence'] for m in metrics_list])\n",
                "    avg_torso_occ = np.mean([m['torso_occlusion_rate'] for m in metrics_list])\n",
                "    \n",
                "    results = {\n",
                "        'dataset': dataset_name,\n",
                "        'images_analyzed': len(metrics_list),\n",
                "        'avg_occlusion_rate': float(avg_occlusion),\n",
                "        'avg_keypoint_confidence': float(avg_confidence),\n",
                "        'torso_occlusion_rate': float(avg_torso_occ)\n",
                "    }\n",
                "    \n",
                "    print(f\"Results for {dataset_name}:\")\n",
                "    print(f\"  - Avg Occlusion Rate: {avg_occlusion:.2%} (Lower is better/less occluded)\")\n",
                "    print(f\"  - Avg Confidence: {avg_confidence:.4f}\")\n",
                "    \n",
                "    return results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "all_results = {}\n",
                "for name, path in config.items():\n",
                "    if name in ['vitonhd', 'deepfashion1', 'dresscode']:\n",
                "        res = evaluate_occlusion(name.upper(), path, max_images=300)\n",
                "        if res:\n",
                "            all_results[name] = res"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if all_results:\n",
                "    datasets = list(all_results.keys())\n",
                "    occ_rates = [all_results[d]['avg_occlusion_rate'] for d in datasets]\n",
                "    confidences = [all_results[d]['avg_keypoint_confidence'] for d in datasets]\n",
                "    \n",
                "    fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
                "    \n",
                "    ax[0].bar(datasets, occ_rates, color=['blue', 'red', 'green'][:len(datasets)])\n",
                "    ax[0].set_title(\"Average Occlusion Rate (Blocking)\")\n",
                "    ax[0].set_ylabel(\"Rate (0-1)\")\n",
                "    \n",
                "    ax[1].bar(datasets, confidences, color=['blue', 'red', 'green'][:len(datasets)])\n",
                "    ax[1].set_title(\"Average Keypoint Confidence\")\n",
                "    ax[1].set_ylabel(\"Confidence (0-1)\")\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save\n",
                "out_path = Path('/content/datasets/occlusion_results.json')\n",
                "with open(out_path, 'w') as f:\n",
                "    json.dump(all_results, f, indent=2)\n",
                "print(f\"Saved to {out_path}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}